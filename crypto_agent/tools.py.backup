"""
Trading Agent Tools
4 core tools that power the intelligent trading decision agent
"""
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
from .database import AgentDatabase
from .config import (
    MODEL_WEIGHTS, QUALITY_WEIGHTS, SIGNAL_THRESHOLDS,
    REGIME_CONFIG, TIMEFRAME_WEIGHTS, PREDICTION_LIMITS,
    POSITION_SIZING
)

logger = logging.getLogger(__name__)


class SmartConsensusAnalyzer:
    """
    Tool 1: Smart Consensus Analyzer
    
    Intelligently interprets contradictory model predictions by:
    - Weighting models by recent performance
    - Understanding model-specific behaviors
    - Considering confidence distribution
    - Checking multi-timeframe alignment
    """
    
    def __init__(self, db: AgentDatabase):
        """Initialize consensus analyzer"""
        self.db = db
        self.logger = logging.getLogger(__name__)  # FIX: Add logger
        logger.info("üß† Smart Consensus Analyzer initialized")
    
    def analyze(self, symbol: str, timeframe: str) -> Dict:
        """
        Analyze model predictions and generate weighted consensus
        
        Args:
            symbol: Trading pair (e.g., 'BTC/USDT')
            timeframe: Timeframe (e.g., '1h', '4h')
            
        Returns:
            Dict with consensus recommendation, confidence, and reasoning
        """
        logger.info(f"üîç Analyzing consensus for {symbol} {timeframe}")
        
        # Get ML predictions from all models
        predictions = self.db.get_ml_predictions(symbol, timeframe)
        
        # DEBUG: Log what we got
        self.logger.info(f"üêõ DEBUG: Predictions shape: {predictions.shape}")
        self.logger.info(f"üêõ DEBUG: Predictions columns: {predictions.columns.tolist()}")
        if not predictions.empty:
            self.logger.info(f"üêõ DEBUG: First prediction: {predictions.iloc[0].to_dict()}")
        
        if predictions.empty:
            logger.warning(f"‚ö†Ô∏è No predictions available for {symbol} {timeframe}")
            return {
                'recommendation': 'HOLD',
                'confidence': 0.0,
                'reasoning': 'No ML predictions available',
                'models_used': [],
                'consensus_strength': 0.0
            }
        
        # Get model performance to weight predictions
        performance = self.db.get_model_performance(symbol, timeframe, days_back=30)
        
        # Calculate weighted consensus
        consensus = self._calculate_weighted_consensus(
            predictions, performance, timeframe
        )
        
        # Check multi-timeframe alignment
        mtf_alignment = self._check_multitimeframe_alignment(symbol, timeframe)
        consensus['mtf_alignment'] = mtf_alignment
        
        # Adjust confidence based on alignment
        if mtf_alignment['alignment_score'] > 0.7:
            consensus['confidence'] = min(0.95, consensus['confidence'] * 1.15)
            consensus['reasoning'] += f" Multi-timeframe alignment strong ({mtf_alignment['alignment_score']:.0%})."
        elif mtf_alignment['alignment_score'] < 0.3:
            consensus['confidence'] *= 0.85
            consensus['reasoning'] += f" Multi-timeframe conflict detected ({mtf_alignment['alignment_score']:.0%})."
        
        logger.info(f"‚úÖ Consensus: {consensus['recommendation']} (confidence: {consensus['confidence']:.2%})")
        
        return consensus
    
    def _calculate_weighted_consensus(self, predictions: pd.DataFrame,
                                   performance: pd.DataFrame,
                                   timeframe: str) -> Dict:
        """
        Calculate weighted consensus from model predictions
        Adjusts weights based on recent model performance
        """
        
        if predictions.empty:
            return {
                'recommendation': 'HOLD',
                'confidence': 0.0,
                'weighted_price_change': 0.0,
                'models_used': [],
                'reasoning': 'No ML predictions available'
            }
        
        # Get base weights for this timeframe
        base_weights = MODEL_WEIGHTS.get(timeframe, MODEL_WEIGHTS['1h'])
        
        # Convert predictions to list of dicts
        models_used = []
        total_weight = 0
        weighted_price_sum = 0
        directions = []
        
        for _, pred in predictions.iterrows():
            model_type = pred['model_type']
            
            # Get base weight
            weight = base_weights.get(model_type, 0)
            
            if weight == 0:
                continue
            
            # Adjust weight based on recent performance (if available)
            if not performance.empty and 'model_type' in performance.columns:
                try:
                    perf_row = performance[performance['model_type'] == model_type]
                    if not perf_row.empty:
                        accuracy = perf_row.iloc[0]['accuracy']
                        # Boost or reduce weight based on accuracy
                        # If accuracy > 52.5%, increase weight; if < 52.5%, decrease
                        performance_multiplier = 1.0 + ((accuracy - 0.525) * 2)
                        performance_multiplier = max(0.5, min(1.5, performance_multiplier))
                        weight *= performance_multiplier
                except Exception as e:
                    self.logger.debug(f"Could not adjust weight for {model_type}: {e}")
                    # Continue with base weight
            
            # Clip predicted price change to reasonable limits
            price_change = pred.get('predicted_change_pct', 0)
            max_change = PREDICTION_LIMITS.get(timeframe, 0.05)
            price_change = max(-max_change, min(max_change, price_change))
            
            # Accumulate
            total_weight += weight
            weighted_price_sum += price_change * weight
            directions.append(pred.get('predicted_direction', 'NEUTRAL'))
            
            models_used.append({
                'model': model_type,
                'direction': pred.get('predicted_direction', 'NEUTRAL'),
                'price_change': price_change,
                'confidence': pred.get('confidence_score', 0),
                'weight': weight
            })
        
        if total_weight == 0 or not models_used:
            return {
                'recommendation': 'HOLD',
                'confidence': 0.0,
                'weighted_price_change': 0.0,
                'models_used': [],
                'reasoning': 'No valid model predictions'
            }
        
        # Calculate weighted average price change
        weighted_price_change = weighted_price_sum / total_weight
        
        # Determine recommendation based on weighted change
        if weighted_price_change > 0.01:  # > 1%
            recommendation = 'STRONG_BUY'
        elif weighted_price_change > 0.005:  # > 0.5%
            recommendation = 'BUY'
        elif weighted_price_change < -0.01:  # < -1%
            recommendation = 'STRONG_SELL'
        elif weighted_price_change < -0.005:  # < -0.5%
            recommendation = 'SELL'
        else:
            recommendation = 'HOLD'
        
        # Calculate confidence based on model agreement
        direction_counts = {
            'UP': directions.count('UP'),
            'DOWN': directions.count('DOWN'),
            'NEUTRAL': directions.count('NEUTRAL')
        }
        
        total_models = len(directions)
        max_agreement = max(direction_counts.values()) if direction_counts else 0
        agreement_rate = max_agreement / total_models if total_models > 0 else 0
        
        # Confidence is combination of agreement and magnitude
        magnitude_confidence = min(abs(weighted_price_change) * 10, 1.0)  # Max 1.0
        confidence = (agreement_rate * 0.6 + magnitude_confidence * 0.4)
        
        # Check multi-timeframe alignment (if we have predictions)
        alignment_score = self._check_timeframe_alignment(
            predictions.iloc[0]['symbol'], timeframe
        )
        
        # Adjust confidence based on alignment
        confidence *= (0.8 + alignment_score * 0.2)
        
        # Generate reasoning
        reasoning = self._generate_consensus_reasoning(
            models_used, recommendation, confidence, alignment_score
        )
        
        return {
            'recommendation': recommendation,
            'confidence': confidence,
            'weighted_price_change': weighted_price_change,
            'models_used': models_used,
            'alignment_score': alignment_score,
            'reasoning': reasoning
        }
        
    def _check_multitimeframe_alignment(self, symbol: str,
                                       primary_timeframe: str) -> Dict:
        """Check if other timeframes agree with primary timeframe signal"""
        
        timeframes = ['15m', '1h', '4h', '1d']
        if primary_timeframe in timeframes:
            timeframes.remove(primary_timeframe)
        
        # Get primary direction
        primary_pred = self.db.get_ml_predictions(symbol, primary_timeframe)
        if primary_pred.empty:
            return {'alignment_score': 0.5, 'aligned_timeframes': []}
        
        # Get dominant direction from primary
        primary_directions = primary_pred['predicted_direction'].value_counts()
        if primary_directions.empty:
            return {'alignment_score': 0.5, 'aligned_timeframes': []}
        
        primary_direction = primary_directions.index[0]
        
        # Check other timeframes
        aligned_count = 0
        total_count = 0
        aligned_timeframes = []
        
        for tf in timeframes[:3]:  # Check max 3 other timeframes
            tf_pred = self.db.get_ml_predictions(symbol, tf)
            if not tf_pred.empty:
                tf_directions = tf_pred['predicted_direction'].value_counts()
                if not tf_directions.empty:
                    tf_direction = tf_directions.index[0]
                    total_count += 1
                    
                    if tf_direction == primary_direction:
                        aligned_count += 1
                        aligned_timeframes.append(tf)
        
        alignment_score = aligned_count / total_count if total_count > 0 else 0.5
        
        return {
            'alignment_score': alignment_score,
            'aligned_timeframes': aligned_timeframes,
            'total_checked': total_count
        }
    
    def _generate_reasoning(self, models_used: List[Dict],
                           dominant_direction: str,
                           direction_votes: Dict,
                           price_change: float,
                           timeframe: str) -> str:
        """Generate human-readable reasoning for the consensus"""
        
        if not models_used:
            return "No model predictions available."
        
        # Count agreements
        agree_count = sum(1 for m in models_used if m['direction'] == dominant_direction)
        total_count = len(models_used)
        
        # Build reasoning
        parts = []
        
        # Model agreement
        if agree_count == total_count:
            parts.append(f"All {total_count} models agree on {dominant_direction} direction")
        elif agree_count / total_count >= 0.66:
            parts.append(f"Strong consensus: {agree_count}/{total_count} models predict {dominant_direction}")
        else:
            parts.append(f"Weak consensus: {agree_count}/{total_count} models predict {dominant_direction}")
        
        # Highlight model contributions
        top_models = sorted(models_used, key=lambda x: x['weight'], reverse=True)[:2]
        model_names = [m['model'].upper() for m in top_models]
        parts.append(f"Led by {', '.join(model_names)}")
        
        # Price change expectation
        if abs(price_change) > 0.01:  # > 1%
            parts.append(f"expecting {price_change:+.2%} move")
        
        # Recent performance note
        avg_confidence = np.mean([m['confidence'] for m in models_used])
        if avg_confidence > 0.65:
            parts.append("with high model confidence")
        elif avg_confidence < 0.45:
            parts.append("but model confidence is low")
        
        return ". ".join(parts) + "."


class TradeQualityScorer:
    """
    Tool 2: Trade Quality Scorer
    
    Ranks every signal from 0-100 based on:
    1. Model consensus strength
    2. Historical win rate at this confidence level
    3. Multi-timeframe alignment
    4. Recent model performance
    5. Technical indicator confirmation
    6. Signal strength vs noise
    7. Data freshness
    8. Trading frequency (avoid overtrading)
    9. BTC correlation (independent movement)
    """
    
    def __init__(self, db: AgentDatabase):
        """Initialize quality scorer"""
        self.db = db
        logger.info("‚≠ê Trade Quality Scorer initialized")
    
    def score(self, symbol: str, timeframe: str,
             consensus: Dict) -> Dict:
        """
        Score the quality of a trading signal
        
        Args:
            symbol: Trading pair
            timeframe: Timeframe
            consensus: Output from SmartConsensusAnalyzer
            
        Returns:
            Dict with quality score (0-100), grade, breakdown, and position sizing
        """
        logger.info(f"üìä Scoring trade quality for {symbol} {timeframe}")
        
        # Calculate individual dimension scores
        scores = {}
        
        # 1. Model consensus (0-10 points)
        scores['model_consensus'] = self._score_model_consensus(consensus)
        
        # 2. Historical win rate (0-10 points)
        scores['historical_winrate'] = self._score_historical_winrate(
            symbol, timeframe, consensus
        )
        
        # 3. Multi-timeframe alignment (0-10 points)
        scores['timeframe_alignment'] = self._score_timeframe_alignment(consensus)
        
        # 4. Recent model performance (0-10 points)
        scores['model_performance'] = self._score_model_performance(
            symbol, timeframe, consensus
        )
        
        # 5. Technical confirmation (0-10 points)
        scores['technical_confirmation'] = self._score_technical_confirmation(
            symbol, timeframe, consensus
        )
        
        # 6. Signal strength (0-10 points)
        scores['signal_strength'] = self._score_signal_strength(consensus)
        
        # 7. Data freshness (0-10 points)
        scores['data_freshness'] = self._score_data_freshness(symbol, timeframe)
        
        # 8. Trading frequency (0-10 points)
        scores['trading_frequency'] = self._score_trading_frequency(symbol, timeframe)
        
        # 9. BTC correlation (0-10 points)
        scores['btc_correlation'] = self._score_btc_correlation(symbol, timeframe)
        
        # Calculate weighted total score (0-100)
        total_score = 0
        for dimension, score in scores.items():
            weight = QUALITY_WEIGHTS.get(dimension, 10) / 10.0
            total_score += score * weight
        
        # Determine grade
        grade = self._get_grade(total_score)
        
        # Get position sizing recommendation
        position_size = self._get_position_sizing(total_score)
        
        # Generate detailed breakdown
        breakdown = {
            dimension: {
                'score': score,
                'weight': QUALITY_WEIGHTS.get(dimension, 10),
                'contribution': score * QUALITY_WEIGHTS.get(dimension, 10) / 10.0
            }
            for dimension, score in scores.items()
        }
        
        result = {
            'quality_score': int(round(total_score)),
            'grade': grade,
            'position_size_pct': position_size,
            'breakdown': breakdown,
            'strengths': self._identify_strengths(breakdown),
            'weaknesses': self._identify_weaknesses(breakdown)
        }
        
        logger.info(f"‚úÖ Quality Score: {result['quality_score']}/100 (Grade: {grade})")
        
        return result
    
    def _score_model_consensus(self, consensus: Dict) -> float:
        """Score based on how many models agree (0-10)"""
        consensus_strength = consensus.get('consensus_strength', 0.5)
        
        # Perfect consensus (100%) = 10 points
        # 50% consensus = 0 points
        score = max(0, (consensus_strength - 0.5) * 20)
        return min(10, score)
    
    def _score_historical_winrate(self, symbol: str, timeframe: str,
                                  consensus: Dict) -> float:
        """Score based on historical win rate at similar confidence (0-10)"""
        
        # Get historical signals
        historical = self.db.get_historical_signals(symbol, timeframe, days_back=90)
        
        if historical.empty:
            return 5.0  # Neutral score if no history
        
        # Filter to similar confidence range
        confidence = consensus.get('confidence', 0.5)
        confidence_range = (confidence - 0.1, confidence + 0.1)
        
        similar_signals = historical[
            (historical['confidence'] >= confidence_range[0]) &
            (historical['confidence'] <= confidence_range[1])
        ]
        
        if len(similar_signals) < 3:
            return 5.0  # Not enough data
        
        # Calculate win rate
        wins = (similar_signals['outcome_4h'] == 'WIN').sum()
        total = len(similar_signals)
        win_rate = wins / total
        
        # Win rate > 60% = high score
        # Win rate < 40% = low score
        if win_rate >= 0.70:
            score = 10
        elif win_rate >= 0.60:
            score = 8
        elif win_rate >= 0.50:
            score = 6
        elif win_rate >= 0.40:
            score = 4
        else:
            score = 2
        
        return float(score)
    
    def _score_timeframe_alignment(self, consensus: Dict) -> float:
        """Score based on multi-timeframe alignment (0-10)"""
        
        mtf = consensus.get('mtf_alignment', {})
        alignment_score = mtf.get('alignment_score', 0.5)
        
        # Perfect alignment = 10 points
        # 50% alignment = 5 points
        # No alignment = 0 points
        return alignment_score * 10
    
    def _score_model_performance(self, symbol: str, timeframe: str,
                                consensus: Dict) -> float:
        """Score based on recent model accuracy (0-10)"""
        
        performance = self.db.get_model_performance(symbol, timeframe, days_back=30)
        
        if performance.empty:
            return 5.0  # Neutral if no performance data
        
        # Get models used in consensus
        models_used = [m['model'] for m in consensus.get('models_used', [])]
        
        # Calculate weighted average accuracy
        total_accuracy = 0
        total_weight = 0
        
        for model_name in models_used:
            model_perf = performance[performance['model_type'].str.lower() == model_name]
            if not model_perf.empty and model_perf['accuracy'].notna().any():
                accuracy = float(model_perf['accuracy'].iloc[0])
                total_accuracy += accuracy
                total_weight += 1
        
        if total_weight == 0:
            return 5.0
        
        avg_accuracy = total_accuracy / total_weight
        
        # Accuracy > 60% = excellent
        # Accuracy > 55% = good
        # Accuracy > 50% = fair
        # Accuracy < 50% = poor
        if avg_accuracy >= 0.60:
            return 10.0
        elif avg_accuracy >= 0.55:
            return 8.0
        elif avg_accuracy >= 0.52:
            return 6.0
        elif avg_accuracy >= 0.50:
            return 4.0
        else:
            return 2.0
    
    def _score_technical_confirmation(self, symbol: str, timeframe: str,
                                     consensus: Dict) -> float:
        """Score based on technical indicator support (0-10)"""
        
        # Get technical indicators
        indicators = self.db.get_technical_indicators(symbol, timeframe, limit=5)
        
        if indicators.empty:
            return 5.0  # Neutral if no indicators
        
        latest = indicators.iloc[0]
        direction = consensus.get('recommendation', 'HOLD')
        
        confirmations = 0
        total_checks = 0
        
        # RSI check
        if pd.notna(latest.get('rsi_14')):
            rsi = latest['rsi_14']
            total_checks += 1
            if direction in ['BUY', 'STRONG_BUY'] and rsi < 45:
                confirmations += 1
            elif direction in ['SELL', 'STRONG_SELL'] and rsi > 55:
                confirmations += 1
            elif direction == 'HOLD' and 40 <= rsi <= 60:
                confirmations += 1
        
        # MACD check
        if pd.notna(latest.get('macd_line')) and pd.notna(latest.get('macd_signal')):
            macd_bullish = latest['macd_line'] > latest['macd_signal']
            total_checks += 1
            if direction in ['BUY', 'STRONG_BUY'] and macd_bullish:
                confirmations += 1
            elif direction in ['SELL', 'STRONG_SELL'] and not macd_bullish:
                confirmations += 1
        
        # Bollinger Bands check
        if pd.notna(latest.get('bb_upper')) and pd.notna(latest.get('bb_lower')):
            # Get current price
            price = self.db.get_latest_price(symbol, timeframe)
            if price:
                total_checks += 1
                bb_position = (price - latest['bb_lower']) / (latest['bb_upper'] - latest['bb_lower'])
                
                if direction in ['BUY', 'STRONG_BUY'] and bb_position < 0.3:
                    confirmations += 1
                elif direction in ['SELL', 'STRONG_SELL'] and bb_position > 0.7:
                    confirmations += 1
        
        if total_checks == 0:
            return 5.0
        
        confirmation_rate = confirmations / total_checks
        return confirmation_rate * 10
    
    def _score_signal_strength(self, consensus: Dict) -> float:
        """Score based on signal confidence vs historical noise (0-10)"""
        
        confidence = consensus.get('confidence', 0.5)
        
        # High confidence = strong signal
        # Confidence > 0.7 = 10 points
        # Confidence 0.5 = 5 points
        # Confidence < 0.3 = 0 points
        
        if confidence >= 0.70:
            return 10.0
        elif confidence >= 0.60:
            return 8.0
        elif confidence >= 0.50:
            return 6.0
        elif confidence >= 0.40:
            return 4.0
        else:
            return max(0, confidence * 10)
    
    def _score_data_freshness(self, symbol: str, timeframe: str) -> float:
        """Score based on how recent the data is (0-10)"""
        
        # Get latest price data
        df = self.db.get_price_history(symbol, timeframe, hours_back=24)
        
        if df.empty:
            return 0.0
        
        latest_timestamp = pd.to_datetime(df['timestamp'].iloc[-1])
        now = datetime.now()
        age_minutes = (now - latest_timestamp).total_seconds() / 60
        
        # Timeframe-specific freshness requirements
        max_age = {
            '5m': 10,    # 10 minutes max
            '15m': 30,   # 30 minutes max
            '1h': 120,   # 2 hours max
            '4h': 480,   # 8 hours max
            '1d': 1440   # 24 hours max
        }.get(timeframe, 120)
        
        if age_minutes <= max_age * 0.5:
            return 10.0
        elif age_minutes <= max_age:
            return 7.0
        elif age_minutes <= max_age * 2:
            return 4.0
        else:
            return 1.0
    
    def _score_trading_frequency(self, symbol: str, timeframe: str) -> float:
        """Score based on recent trading frequency - penalize overtrading (0-10)"""
        
        # Get recent recommendations
        recent = self.db.get_historical_signals(symbol, timeframe, days_back=7)
        
        if recent.empty:
            return 10.0  # No recent trades = good
        
        # Count trades in last 24 hours
        cutoff = datetime.now() - timedelta(hours=24)
        recent['timestamp'] = pd.to_datetime(recent['timestamp'])
        recent_24h = recent[recent['timestamp'] >= cutoff]
        
        trade_count = len(recent_24h)
        
        # Penalize frequent trading
        if trade_count == 0:
            return 10.0
        elif trade_count == 1:
            return 8.0
        elif trade_count == 2:
            return 6.0
        elif trade_count == 3:
            return 4.0
        else:
            return 2.0  # Too many trades
    
    def _score_btc_correlation(self, symbol: str, timeframe: str) -> float:
        """Score based on independence from BTC (0-10)"""
        
        if symbol == 'BTC/USDT':
            return 10.0  # BTC is always independent from itself
        
        # Get price history for this symbol and BTC
        symbol_prices = self.db.get_price_history(symbol, timeframe, hours_back=168)
        btc_prices = self.db.get_price_history('BTC/USDT', timeframe, hours_back=168)
        
        if symbol_prices.empty or btc_prices.empty:
            return 5.0  # Neutral if no data
        
        # Calculate returns
        symbol_prices = symbol_prices.set_index('timestamp')
        btc_prices = btc_prices.set_index('timestamp')
        
        # Align timestamps
        aligned = symbol_prices.join(btc_prices, how='inner', rsuffix='_btc')
        
        if len(aligned) < 20:
            return 5.0
        
        symbol_returns = aligned['close'].pct_change()
        btc_returns = aligned['close_btc'].pct_change()
        
        # Calculate correlation
        correlation = symbol_returns.corr(btc_returns)
        
        # High independence = high score
        # correlation < 0.5 = very independent = 10 points
        # correlation > 0.9 = very correlated = 2 points
        
        if pd.isna(correlation):
            return 5.0
        
        if correlation < 0.3:
            return 10.0
        elif correlation < 0.5:
            return 8.0
        elif correlation < 0.7:
            return 6.0
        elif correlation < 0.85:
            return 4.0
        else:
            return 2.0
    
    def _get_grade(self, score: float) -> str:
        """Convert numeric score to letter grade"""
        if score >= 90:
            return 'A+'
        elif score >= 85:
            return 'A'
        elif score >= 80:
            return 'A-'
        elif score >= 75:
            return 'B+'
        elif score >= 70:
            return 'B'
        elif score >= 65:
            return 'B-'
        elif score >= 60:
            return 'C+'
        elif score >= 55:
            return 'C'
        elif score >= 50:
            return 'C-'
        else:
            return 'D'
    
    def _get_position_sizing(self, score: float) -> Tuple[float, float]:
        """Get recommended position size based on quality score"""
        if score >= 90:
            return POSITION_SIZING['quality_90_plus']
        elif score >= 80:
            return POSITION_SIZING['quality_80_89']
        elif score >= 70:
            return POSITION_SIZING['quality_70_79']
        elif score >= 60:
            return POSITION_SIZING['quality_60_69']
        else:
            return POSITION_SIZING['quality_below_60']
    
    def _identify_strengths(self, breakdown: Dict) -> List[str]:
        """Identify top strengths from breakdown"""
        strengths = []
        
        for dimension, data in breakdown.items():
            if data['score'] >= 8.0:
                strengths.append(dimension.replace('_', ' ').title())
        
        return strengths[:3]  # Top 3
    
    def _identify_weaknesses(self, breakdown: Dict) -> List[str]:
        """Identify weaknesses from breakdown"""
        weaknesses = []
        
        for dimension, data in breakdown.items():
            if data['score'] <= 4.0:
                weaknesses.append(dimension.replace('_', ' ').title())
        
        return weaknesses[:3]  # Top 3


class MarketContextAnalyzer:
    """
    Tool 3: Market Context Analyzer
    
    Detects current market regime and provides regime-specific recommendations:
    - Trending Bull
    - Trending Bear
    - Ranging/Choppy
    - High Volatility
    """
    
    def __init__(self, db: AgentDatabase):
        """Initialize market context analyzer"""
        self.db = db
        logger.info("üåç Market Context Analyzer initialized")
    
    def analyze(self, symbol: str = 'BTC/USDT') -> Dict:
        """
        Analyze current market regime
        
        Args:
            symbol: Symbol to analyze (default BTC as market leader)
            
        Returns:
            Dict with regime, characteristics, and recommendations
        """
        logger.info(f"üîç Analyzing market regime for {symbol}")
        
        # Get price history
        df = self.db.get_price_history(
            symbol, 
            '1d',  # Use daily for regime detection
            hours_back=REGIME_CONFIG['trend_lookback_days'] * 24
        )
        
        if df.empty or len(df) < 7:
            logger.warning("‚ö†Ô∏è Insufficient data for regime analysis")
            return self._default_regime()
        
        # Calculate trend
        trend = self._calculate_trend(df)
        
        # Calculate volatility
        volatility = self._calculate_volatility(df)
        
        # Determine regime
        regime = self._determine_regime(trend, volatility)
        
        # Get regime-specific recommendations
        recommendations = self._get_regime_recommendations(regime, trend, volatility)
        
        # Analyze market breadth (all symbols)
        breadth = self._analyze_market_breadth()
        
        result = {
            'regime': regime['type'],
            'confidence': regime['confidence'],
            'characteristics': {
                'trend_direction': trend['direction'],
                'trend_strength': trend['strength'],
                'volatility_level': volatility['level'],
                'volatility_value': volatility['value'],
                'days_in_trend': trend['duration_days'],
                'market_breadth': breadth
            },
            'recommendations': recommendations,
            'risk_level': self._assess_risk_level(regime, volatility)
        }
        
        logger.info(f"‚úÖ Market Regime: {regime['type']} (confidence: {regime['confidence']:.0%})")
        
        return result
    
    def _calculate_trend(self, df: pd.DataFrame) -> Dict:
        """Calculate trend direction and strength"""
        
        df = df.copy()
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df = df.sort_values('timestamp')
        
        # Calculate price change over period
        first_price = df['close'].iloc[0]
        last_price = df['close'].iloc[-1]
        total_change = (last_price - first_price) / first_price
        
        # Calculate moving average slope
        df['ma_7'] = df['close'].rolling(7).mean()
        ma_change = (df['ma_7'].iloc[-1] - df['ma_7'].iloc[0]) / df['ma_7'].iloc[0]
        
        # Determine direction
        if total_change > 0.05:  # > 5% up
            direction = 'bullish'
        elif total_change < -0.05:  # > 5% down
            direction = 'bearish'
        else:
            direction = 'neutral'
        
        # Calculate strength (0-1)
        strength = min(abs(total_change) / 0.15, 1.0)  # Normalize to 15% move
        
        # Calculate higher highs / lower lows
        highs = df['high'].rolling(3).max()
        lows = df['low'].rolling(3).min()
        
        higher_highs = (highs.iloc[-1] > highs.iloc[-4]) if len(highs) >= 4 else False
        lower_lows = (lows.iloc[-1] < lows.iloc[-4]) if len(lows) >= 4 else False
        
        return {
            'direction': direction,
            'strength': strength,
            'total_change_pct': total_change * 100,
            'ma_change_pct': ma_change * 100,
            'higher_highs': higher_highs,
            'lower_lows': lower_lows,
            'duration_days': len(df)
        }
    
    def _calculate_volatility(self, df: pd.DataFrame) -> Dict:
        """Calculate market volatility"""
        
        df = df.copy()
        
        # Calculate daily returns
        df['returns'] = df['close'].pct_change()
        
        # Calculate volatility (standard deviation of returns)
        volatility_value = df['returns'].std()
        
        # Classify volatility level
        if volatility_value > REGIME_CONFIG['high_volatility_threshold']:
            level = 'high'
        elif volatility_value < REGIME_CONFIG['low_volatility_threshold']:
            level = 'low'
        else:
            level = 'moderate'
        
        # Calculate average true range (ATR-like measure)
        df['high_low'] = df['high'] - df['low']
        avg_range = df['high_low'].mean() / df['close'].mean()
        
        return {
            'value': volatility_value,
            'level': level,
            'avg_daily_range_pct': avg_range * 100
        }
    
    def _determine_regime(self, trend: Dict, volatility: Dict) -> Dict:
        """Determine market regime from trend and volatility"""
        
        direction = trend['direction']
        strength = trend['strength']
        vol_level = volatility['level']
        
        # High volatility overrides everything
        if vol_level == 'high':
            return {
                'type': 'High Volatility',
                'confidence': 0.9
            }
        
        # Trending markets
        if strength > 0.6:
            if direction == 'bullish':
                return {
                    'type': 'Trending Bull',
                    'confidence': strength
                }
            elif direction == 'bearish':
                return {
                    'type': 'Trending Bear',
                    'confidence': strength
                }
        
        # Ranging market
        return {
            'type': 'Ranging',
            'confidence': 1.0 - strength
        }
    
    def _get_regime_recommendations(self, regime: Dict,
                                   trend: Dict, volatility: Dict) -> Dict:
        """Get trading recommendations based on regime"""
        
        regime_type = regime['type']
        
        if regime_type == 'Trending Bull':
            return {
                'buy_signals': 'Trust with increased position size (1.2x normal)',
                'sell_signals': 'Be cautious - many are false reversals. Demand quality > 80',
                'stop_loss': 'Trail stops tighter (+15% from normal)',
                'timeframes': 'Prioritize 4h and 1d signals over 15m noise',
                'strategy': 'Trend following - buy dips, avoid shorting',
                'position_adjustment': 1.2
            }
        
        elif regime_type == 'Trending Bear':
            return {
                'buy_signals': 'Be very cautious - demand quality > 85',
                'sell_signals': 'Trust with increased position size (1.2x normal)',
                'stop_loss': 'Use wider stops for shorts (-15% from normal)',
                'timeframes': 'Prioritize 4h and 1d signals',
                'strategy': 'Short rallies, avoid catching falling knives',
                'position_adjustment': 1.2
            }
        
        elif regime_type == 'Ranging':
            return {
                'buy_signals': 'Buy at support levels with quality > 70',
                'sell_signals': 'Sell at resistance with quality > 70',
                'stop_loss': 'Tight stops - range can break quickly',
                'timeframes': 'Lower timeframes (1h, 15m) more relevant',
                'strategy': 'Mean reversion - fade extremes',
                'position_adjustment': 0.8
            }
        
        elif regime_type == 'High Volatility':
            return {
                'buy_signals': 'Reduce position sizes by 50%',
                'sell_signals': 'Reduce position sizes by 50%',
                'stop_loss': 'Use wider stops to avoid whipsaws',
                'timeframes': 'Higher timeframes only (4h, 1d)',
                'strategy': 'Wait for volatility to subside, or trade breakouts only',
                'position_adjustment': 0.5
            }
        
        else:
            return {
                'buy_signals': 'Standard approach',
                'sell_signals': 'Standard approach',
                'stop_loss': 'Standard stops',
                'timeframes': 'All timeframes valid',
                'strategy': 'Balanced approach',
                'position_adjustment': 1.0
            }
    
    def _analyze_market_breadth(self) -> Dict:
        """Analyze how many symbols are trending in same direction"""
        
        from .config import SYMBOLS
        
        bullish_count = 0
        bearish_count = 0
        neutral_count = 0
        
        for symbol in SYMBOLS:
            df = self.db.get_price_history(symbol, '1d', hours_back=168)
            if not df.empty and len(df) >= 7:
                trend = self._calculate_trend(df)
                
                if trend['direction'] == 'bullish':
                    bullish_count += 1
                elif trend['direction'] == 'bearish':
                    bearish_count += 1
                else:
                    neutral_count += 1
        
        total = bullish_count + bearish_count + neutral_count
        
        if total == 0:
            return {'status': 'unknown'}
        
        return {
            'bullish_pct': (bullish_count / total) * 100,
            'bearish_pct': (bearish_count / total) * 100,
            'neutral_pct': (neutral_count / total) * 100,
            'dominant_direction': 'bullish' if bullish_count > bearish_count else 'bearish' if bearish_count > bullish_count else 'mixed'
        }
    
    def _assess_risk_level(self, regime: Dict, volatility: Dict) -> str:
        """Assess overall risk level"""
        
        regime_type = regime['type']
        vol_level = volatility['level']
        
        if regime_type == 'High Volatility':
            return 'VERY HIGH'
        elif vol_level == 'high':
            return 'HIGH'
        elif regime_type in ['Trending Bull', 'Trending Bear']:
            return 'MODERATE'
        else:
            return 'LOW'
    
    def _default_regime(self) -> Dict:
        """Return default regime when analysis fails"""
        return {
            'regime': 'Unknown',
            'confidence': 0.0,
            'characteristics': {},
            'recommendations': {
                'buy_signals': 'Use standard approach',
                'sell_signals': 'Use standard approach',
                'stop_loss': 'Standard stops',
                'timeframes': 'All timeframes',
                'strategy': 'Proceed with caution - insufficient data',
                'position_adjustment': 0.8
            },
            'risk_level': 'UNKNOWN'
        }


class PredictionOutcomeTracker:
    """
    Tool 4: Prediction Outcome Tracker
    
    Logs agent recommendations and tracks outcomes for continuous learning
    """
    
    def __init__(self, db: AgentDatabase):
        """Initialize outcome tracker"""
        self.db = db
        logger.info("üìä Prediction Outcome Tracker initialized")
    
    def log_recommendation(self, symbol: str, timeframe: str,
                          recommendation: str, confidence: float,
                          quality_score: int, consensus: Dict,
                          market_regime: str, reasoning: str) -> bool:
        """
        Log a trading recommendation
        
        Args:
            symbol: Trading pair
            timeframe: Timeframe
            recommendation: BUY/SELL/HOLD
            confidence: Confidence score (0-1)
            quality_score: Quality score (0-100)
            consensus: Consensus analyzer output
            market_regime: Current market regime
            reasoning: Human-readable reasoning
            
        Returns:
            True if successfully logged
        """
        
        # Get current price
        current_price = self.db.get_latest_price(symbol, timeframe)
        
        if not current_price:
            logger.warning(f"‚ö†Ô∏è Could not get current price for {symbol}")
            return False
        
        recommendation_data = {
            'timestamp': datetime.now(),
            'symbol': symbol,
            'timeframe': timeframe,
            'recommendation': recommendation,
            'confidence': confidence,
            'quality_score': quality_score,
            'entry_price': current_price,
            'model_predictions': consensus.get('models_used', []),
            'reasoning': reasoning,
            'market_regime': market_regime
        }
        
        success = self.db.save_agent_recommendation(recommendation_data)
        
        if success:
            logger.info(f"üíæ Logged recommendation: {symbol} {timeframe} - {recommendation}")
        
        return success
    
    def get_performance_stats(self, symbol: Optional[str] = None,
                             timeframe: Optional[str] = None,
                             days_back: int = 30) -> Dict:
        """
        Get performance statistics for agent recommendations
        
        Args:
            symbol: Filter by symbol (None = all)
            timeframe: Filter by timeframe (None = all)
            days_back: Days of history to analyze
            
        Returns:
            Dict with performance metrics
        """
        
        # Get historical recommendations
        if symbol and timeframe:
            historical = self.db.get_historical_signals(symbol, timeframe, days_back)
        else:
            # Would need a method to get all signals - for now return empty
            logger.info("‚ÑπÔ∏è Performance stats for all symbols not yet implemented")
            return {}
        
        if historical.empty:
            logger.info(f"‚ÑπÔ∏è No historical recommendations found for analysis")
            return {
                'total_recommendations': 0,
                'note': 'No historical data available'
            }
        
        # Calculate metrics
        total = len(historical)
        
        # 4-hour outcomes (most reliable)
        completed_4h = historical[historical['outcome_4h'].notna()]
        
        if len(completed_4h) == 0:
            return {
                'total_recommendations': total,
                'completed_4h': 0,
                'note': 'No completed outcomes yet'
            }
        
        wins_4h = (completed_4h['outcome_4h'] == 'WIN').sum()
        losses_4h = (completed_4h['outcome_4h'] == 'LOSS').sum()
        
        win_rate_4h = wins_4h / len(completed_4h) if len(completed_4h) > 0 else 0
        
        # Average return
        avg_return = completed_4h['return_4h'].mean() if 'return_4h' in completed_4h else 0
        
        # By quality score
        quality_breakdown = {}
        for quality_range in [(90, 100), (80, 89), (70, 79), (60, 69), (0, 59)]:
            range_signals = completed_4h[
                (completed_4h['quality_score'] >= quality_range[0]) &
                (completed_4h['quality_score'] <= quality_range[1])
            ]
            
            if len(range_signals) > 0:
                range_wins = (range_signals['outcome_4h'] == 'WIN').sum()
                quality_breakdown[f'{quality_range[0]}-{quality_range[1]}'] = {
                    'count': len(range_signals),
                    'win_rate': range_wins / len(range_signals),
                    'avg_return': range_signals['return_4h'].mean()
                }
        
        # Best and worst
        best_trade = completed_4h.loc[completed_4h['return_4h'].idxmax()] if len(completed_4h) > 0 else None
        worst_trade = completed_4h.loc[completed_4h['return_4h'].idxmin()] if len(completed_4h) > 0 else None
        
        return {
            'total_recommendations': total,
            'completed_4h': len(completed_4h),
            'win_rate_4h': win_rate_4h,
            'wins': int(wins_4h),
            'losses': int(losses_4h),
            'avg_return_4h': float(avg_return),
            'quality_breakdown': quality_breakdown,
            'best_trade': {
                'return': float(best_trade['return_4h']),
                'quality_score': int(best_trade['quality_score']),
                'timestamp': str(best_trade['timestamp'])
            } if best_trade is not None else None,
            'worst_trade': {
                'return': float(worst_trade['return_4h']),
                'quality_score': int(worst_trade['quality_score']),
                'timestamp': str(worst_trade['timestamp'])
            } if worst_trade is not None else None
        }
    
    def get_insights(self, symbol: str, timeframe: str,
                    days_back: int = 90) -> List[str]:
        """
        Generate learned insights from historical performance
        
        Args:
            symbol: Trading pair
            timeframe: Timeframe
            days_back: Days to analyze
            
        Returns:
            List of insight strings
        """
        
        stats = self.get_performance_stats(symbol, timeframe, days_back)
        
        if stats.get('total_recommendations', 0) == 0:
            return ["No historical data available for insights"]
        
        insights = []
        
        # Win rate insights
        win_rate = stats.get('win_rate_4h', 0)
        if win_rate > 0.70:
            insights.append(f"Excellent performance: {win_rate:.0%} win rate over {days_back} days")
        elif win_rate > 0.60:
            insights.append(f"Good performance: {win_rate:.0%} win rate")
        elif win_rate < 0.45:
            insights.append(f"Warning: Low win rate ({win_rate:.0%}) - strategy needs review")
        
        # Quality score insights
        quality_breakdown = stats.get('quality_breakdown', {})
        
        best_quality_range = None
        best_win_rate = 0
        
        for quality_range, data in quality_breakdown.items():
            if data['win_rate'] > best_win_rate and data['count'] >= 3:
                best_win_rate = data['win_rate']
                best_quality_range = quality_range
        
        if best_quality_range:
            insights.append(
                f"Quality scores {best_quality_range} have best win rate: {best_win_rate:.0%}"
            )
        
        # Return insights
        avg_return = stats.get('avg_return_4h', 0)
        if avg_return > 0.03:
            insights.append(f"Strong average return: {avg_return:+.2%}")
        elif avg_return < -0.01:
            insights.append(f"Warning: Negative average return ({avg_return:+.2%})")
        
        return insights